---
title: "Homework 7 - BSTA 522"
author: "Matthew Hoctor"
date: "2/15/2022"
output:
  html_document:
    number_sections: no
    theme: lumen
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: no
  pdf_document:
    toc: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# library(dplyr)
# library(readxl)
# library(tidyverse)
library(ggplot2)
# library(CarletonStats)
# library(pwr)
# library(BSDA)
# library(exact2x2)
# library(car)
# library(dvmisc)
# library(emmeans)
# library(gridExtra)
# library(DescTools)
# library(DiagrammeR)
# library(nlme)
# library(doBy)
# library(geepack)
# library(rje)
library(ISLR2)
# library(psych)
# library(MASS)
library(caret)      #for confusionMatrix function
# library(rje)
# library(class)      #for knn function
# library(e1071)      #for naiveBayes function
# library(boot)       #for boot function
# library(covTest)      #for covTest function
# library(leaps)        #for regsubsets function for best subset selection
# library(broom)
# library(glmnet)       #for glmnet() for shrinkage methods
# library(doParallel)   #for parallel computing in glmnet(); does not work
# library(pls)          #for pcr function
# library(qpcR)         #for RSS function
# library(splines)      #for bs() function for basis function of regression splines
# library(quantreg)     #for quantreg() for quantile regression
# library(tree)           #older package for tree regression
library(rpart)          #more maintained package for tree regression
library(rattle)         #for visually appealing tree plotting
library(randomForest)   #for random forest technique
library(party)          #?cforest function for plotting random forests?
library(xgboost)
library(DiagrammeR)
```

# Part B: Question 8.9

- use rpart() and prune(); do not use tree() and cv.tree().
- set.seed(1237)

## Dataset

```{r}
oj <- OJ
```

## a

Create a training set containing a random sample of 800 observations, and a test set containing the remaining observations.

```{r}
set.seed(1237)
train <- sample(1:nrow(oj), 800)

oj.train <- oj[train,]
oj.test <- oj[-train,]
nrow(oj.train)
nrow(oj.test)
```

## b

Fit a tree to the training data, with Purchase as the response
and the other variables as predictors. Use the summary() function
to produce summary statistics about the tree, and describe the
results obtained. What is the training error rate? How many
terminal nodes does the tree have?

What variables are predictors:

```{r}
names(oj)
```

Creating the tree:

```{r}
oj.rpart0 <- rpart(Purchase ~ WeekofPurchase + StoreID + PriceCH + PriceMM + DiscCH + DiscMM + SpecialCH + SpecialMM + LoyalCH + SalePriceMM + SalePriceCH + PriceDiff + Store7 + PctDiscMM + PctDiscCH + ListPriceDiff + STORE,
                   data = oj.train)

printcp(oj.rpart0) # display the results 
# summary(oj.rpart0) # detailed summary of splits
# plotcp(oj.rpart0)  # visualize cross-validation results 

# multiple ways to calculate the training error rate:
class.pred <- table(predict(oj.rpart0, type="class"), oj.train$Purchase)
1-sum(diag(class.pred))/sum(class.pred)

0.385*0.42208
```

We can see that the training error rate is 16.25%, and 5 nodes from 4 splits.

## c

Type in the name of the tree object in order to get a detailed
text output. Pick one of the terminal nodes, and interpret the
information displayed.

```{r}
oj.rpart0
# summary(oj.rpart0)
```

We can see from this output that at terminal node #3 the observations are tested for LoyalCH< 0.450956; 286 observations from the training dataset end up at this node and 63 are misclassified.

## d

Create a plot of the tree, and interpret the results.

Borrowing some code from the script provided in class:

```{r}
plot(oj.rpart0, uniform=TRUE, main="Regression Tree for Purchase ")
text(oj.rpart0, use.n=TRUE, all=TRUE, cex=.8)
```

This plot shows more clearly what is tabulated in the results from part c; namely that there are 5 nodes, and four splits.

## e

Predict the response on the test data, and produce a confusion
matrix comparing the test labels to the predicted test labels.
What is the test error rate?

```{r}
pred.oj.rpart0 <- predict(oj.rpart0,
                          newdata = oj.test,
                          type = "class")
confusionMatrix(pred.oj.rpart0, oj.test$Purchase)
1-0.8037
```

The test error rate is $1-0.8037 = 0.1963$.

## f

Apply the cv.tree() function to the training set in order to
determine the optimal tree size.

We will use prune() instead of cv.tree, to determine the optima tree size:

```{r}
# prune the tree for min CV error
pfit<- prune(oj.rpart0, 
             cp = oj.rpart0$cptable[which.min(oj.rpart0$cptable[,"xerror"]),"CP"])
pfit
```

## g

Produce a plot with tree size on the x-axis and cross-validated
classification error rate on the y-axis.

```{r}
par(mfrow=c(1,3)) # three plots on one page 

#This produces the first plot, asked for in part g
plotcp(pfit)

# This produces the other plots of number of splits vs R2 & X-relative error
rsq.rpart(pfit) # visualize cross-validation results 
```

## h

Which tree size corresponds to the lowest cross-validated classification error rate?

As we can see from the first plot above a tree size of 5 (i.e. 4 splits) results in the lowest CV error rate

## i

Produce a pruned tree corresponding to the optimal tree size
obtained using cross-validation. If cross-validation does not lead
to selection of a pruned tree, then create a pruned tree with five
terminal nodes.

As we can see from the above results, the tree produced by the prune() function has 5  terminal nodes and has the optimal cross-validated error.

## j

Compare the training error rates between the pruned and unpruned trees. Which is higher?

```{r}
par(mfrow=c(1,3)) # three plots on one page 

plot(oj.rpart0, uniform=TRUE, main="Regression Tree for Purchase ")
text(oj.rpart0, use.n=TRUE, all=TRUE, cex=.8)

plot(pfit, uniform=TRUE, main="PrunedRegression Tree for Purchase ")
text(pfit, use.n=TRUE, all=TRUE, cex=.8)
```

As we can see from the above plot, the pruned and unpruned trees are identical.  We can calculate their training error rates:

```{r}
#unpruned training error rate:
class.pred <- table(predict(oj.rpart0, type="class"), oj.train$Purchase)
1-sum(diag(class.pred))/sum(class.pred)


#pruned training error rate:
class.pred <- table(predict(pfit, type="class"), oj.train$Purchase)
1-sum(diag(class.pred))/sum(class.pred)
```

As expected, they are identical.

## k

Compare the test error rates between the pruned and unpruned
trees. Which is higher?

```{r}
pred.pfit <- predict(pfit,
                          newdata = oj.test,
                          type = "class")
confusionMatrix(pred.oj.rpart0, oj.test$Purchase)
confusionMatrix(pred.pfit, oj.test$Purchase)
1-0.8037
```

As expected test error rates are identical.

# Part C

Apply random forest (of your choice) and boosting (of your choice) for the data set in #9 and compare the results (test errors). Which one performs best?

## Random Forest

```{r}
set.seed(1237)
# Create Random forest
oj.cforest0 <- cforest(Purchase ~ ., 
                       data = oj.train,
                       control = cforest_unbiased(ntree = 500))

# Predict test results:
pcforest0 <- predict(oj.cforest0,
                    newdata = oj.test,
                    OOB = TRUE,
                    type = "response")

# Confusion Matrix:
confusionMatrix(pcforest0, oj.test$Purchase)
```

## Boosting

Preparing the datasets:

```{r}
oj2 <- oj
oj2$Store7 <- as.numeric(oj2$Store7)

oj2.train <- oj2[train,]
oj2.test <- oj2[-train,]
```

Gradient boosting:

```{r}
set.seed(1237)

# Creating OJ Purchase as the y-variable:
y <- oj2.train$Purchase
num.class = length(levels(y))
y <- as.numeric(y)-1 #y should start from 0 and numeric, not factor.

# Construct xgb.DMatrix object
dtrain <- xgb.DMatrix(as.matrix(oj2.train[,2:18]), label = y)

param <- list("objective" = "multi:softprob","num_class" = 2)    
          
#param <- list("objective" = "multi:softprob",    
#          "num_class" = 3,          
#          "num_parallel_tree" = 1, 
#          "eval_metric" = "mlogloss",    
#          "nthread" = 8,   
#          "max_depth" = 6,   
#          "eta" = 0.3, #learning rate    
#          "gamma" = 0,    
#          "subsample" = 1,    #subsample ratio
#          "colsample_bytree" = 1,  #subsample ratio of columns
#          "min_child_weight" = 1)

xfit1 <- xgboost(param=param, 
                 dtrain, 
                 nrounds=3) #compare with nround =2, num_parallel_tree seems to be 3 (?)
print(xfit1)
xgb.plot.tree(model = xfit1)
xgb.plot.multi.trees(model = xfit1)
#xgb.dump(xfit1, with_stats = T)
pred = predict(xfit1,dtrain)
pred = matrix(pred,ncol=3,byrow=T)
pclass = apply(pred,1,which.max)
# table(oj2.train$Purchase,pclass)

# confusionMatrix(unique(oj2.train$Purchase)[pclass],oj2.train$Purchase)

mat = xgb.importance(feature_names = colnames(oj[,-5]),model = xfit1)
xgb.plot.importance(importance_matrix = mat)
```

Creating testing set confusion matrix:

```{r}
# Creating OJ Purchase as the y-variable:
y2 <- oj2.test$Purchase
y2 <- as.numeric(y2)-1 #y should start from 0 and numeric, not factor.

dtest <- xgb.DMatrix(as.matrix(oj2.test[,2:18]), label = y2)
pred.test <- predict(xfit1,
                    newdata = dtest,
                    strict_shape = TRUE)

pred_labels <- factor(round(pred.test[2,])+1, labels = c("CH", "MM"))
# pred_labels <- max.col(pred.test) - 1
test_labels <- as.factor(oj2.test$Purchase)

confusionMatrix(pred_labels, oj2.test$Purchase)
```

## Conclusion

The XGBoost method produces the best test set accuracy, with accuracy of 83.3%.
    
# Session Info

```{r}
sessionInfo()
```

# References

1. James G, Witten D, Hastie T, Tibshirani R. An Introduction to Statistical Learning: With Applications in R. 1st ed. 2013, Corr. 7th printing 2017 edition. Springer; 2013.
